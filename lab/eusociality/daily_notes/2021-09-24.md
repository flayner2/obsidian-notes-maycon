# 2021-09-24

- NCBI finished annotating the following genome:
	- [*Vespula pensylvanica*](https://www.ncbi.nlm.nih.gov/genome/?term=txid30213[orgn]);
- Ran `extract_ORF.pl` on the annotation:
```bash
perl ~/eusociality/bin/komodize_genome/bin/extract_ORF.pl genomes/ orfs/
```
- Got the longest seqs and protein ids for it;
```bash
perl ~/lab_utils/get_longest_seq.pl orfs/GCF_014466175.1_ASM1446617v1_genomic.gbff_nt.fasta > longest/GCF_014466175.1_ASM1446617v1_genomic.gbff_nt.fasta.longest

grep ">" longest/GCF_014466175.1_ASM1446617v1_genomic.gbff_nt.fasta.longest | awk -F"protein_id:" '{print $2}' | awk -F"|" '{print $1}' > prot_ids/GCF_014466175.1_ASM1446617v1_genomic.gbff_nt.fasta.longest.ids
```
- Downloaded the proteome;
```bash
perl ~/lab_utils/get_seq_efetch.pl ../prot_ids/GCF_014466175.1_ASM1446617v1_genomic.gbff_nt.fasta.longest.ids
```
- Ran BUSCO for all the species:
```bash
conda activate BUSCO5

nice -n 10 busco -i /home/maycon/eusociality/data/hymenoptera/2021-09-24/proteins/GCF_014466175.1_ASM1446617v1_genomic.gbff_nt.fasta.longest.ids.aa.fa -o vespula_pensylvanica_busco -m prot -l hymenoptera_odb10 -c 50
```
- Updated the sheets with the new BUSCO data;
- Ran InterproScan for the new species:
```bash
conda activate interpro

nice -n 10 interproscan.sh -i ~/eusociality/data/hymenoptera/2021-09-23/proteins/GCF_014825855.1_ASM1482585v1_genomic.gbff_nt.fasta.longest.ids.aa.fa -b ./GCF_014825855 -cpu 50 -goterms -iprlookup -verbose -f tsv > ./GCF_014825855.log
```
- Generated the tabular files from the InterProScan output:
```bash
# for GO
perl ~/eusociality/bin/KOMODO2/bin/utils/parse_interproscan_output_gene2GO.pl GCF_014825855.tsv /home/maycon/eusociality/work/komodo_inputs/gene2go/2021-09-24/
perl ~/eusociality/bin/KOMODO2/bin/utils/parse_interproscan_output_gene2GO.pl GCF_014466175.tsv /home/maycon/eusociality/work/komodo_inputs/gene2go/2021-09-24/

# for Pfam
perl ~/eusociality/bin/KOMODO2/bin/utils/parse_interproscan_output.pl GCF_014825855.tsv "Pfam" /home/maycon/eusociality/work/komodo_inputs/pfam/2021-09-24/
Generating file /home/maycon/eusociality/work/komodo_inputs/pfam/2021-09-24//GCF_014825855.tsv.Pfam.txt
perl ~/eusociality/bin/KOMODO2/bin/utils/parse_interproscan_output.pl GCF_014466175.tsv "Pfam" /home/maycon/eusociality/work/komodo_inputs/pfam/2021-09-24/
Generating file /home/maycon/eusociality/work/komodo_inputs/pfam/2021-09-24//GCF_014466175.tsv.Pfam.txt
```
- Renamed the files to abide to the names in the tree nodes, using the short names defined in the metadata sheet (first updated `names.txt` to contain all the new names):
```bash
# from inside the tabular data directory
~/eusociality/bin/utils/./create_renamed_symlinks.sh ~/eusociality/bin/utils/names.txt .
```
- Created a directory to store all the symlinks to the correct input tabular files that will be used for my masters (`masters_paper_inputs_{gene2go|pfam}`);
- Counted the features in the tabular files:
```bash
# for GO
for file in *.txt; do perl ~/eusociality/bin/KOMODO2/bin/utils/count_GO_gene2GO.pl $file >> counts.txt; done

# for Pfam
for file in *.txt; do printf "$file" >> counts.txt && tail -n +2 $file | wc -l | awk 'OFS="\t" {print $2, $1}' >> counts.txt; done

# to rename
~/eusociality/bin/utils/./rename_counts.sh ~/eusociality/bin/utils/names.txt counts.txt
```
- Renamed the main metadata directory to `masters_paper_metadata`;
- Backed up and updated the metadata files in `/home/maycon/eusociality/data/metadata/masters_paper_metadata` with the data for the new species;
- Removed the metadata files for the 49 species because it may have been misordered. Created new data files for all 7 new species and glued them to the original 44 species metadata files:
```bash
# concatenated and ordered the data files
cat new_5_data.txt new_2_data.txt | sort -k2,1 > new_7_data.txt

# concatenated and ordered the counts files
cat new_2_counts.go new_5_counts.go | sort -k1,1 > new_7_counts.go
cat new_2_counts.pfam new_5_counts.pfam | sort -k1,1 > new_7_counts.pfam

# formatted the raw data file
awk -F'\t' 'OFS="\t" {print $2, $5, 1 + (log($5)/log(10.0)), $6, $4, $1, $3}' new_7_data.txt > new_7_formatted.txt

# pasted the counts with the formatted data files
paste new_7_counts.go new_7_formatted.txt > new_7_go.tsv
paste new_7_counts.pfam new_7_formatted.txt > new_7_pfam.tsv

# edited the files to remove uncessary columns and then...
cat metadata_gene2go_44hymenoptera_final.tsv new_7_go.tsv | sort -k1,1 > metadata_gene2go_51hymenoptera_final.tsv
cat metadata_pfam_44hymenoptera_final.tsv new_7_pfam.tsv | sort -k1,1 > metadata_pfam_51hymenoptera_final.tsv
```
- Started working on getting the BUSCO orthologs for the tree construction:
```bash
# get the ids for the BUSCO orthologs classified as "complete"
for file in $(find ~/eusociality/results/busco_results/2021-08-10/hymenoptera_all_annotated/*/run*/ -name "full_table*.tsv"); do grep -v "^#" ${file} | awk '$2=="Complete" {print $1}' >> complete_busco_ids.txt; done # the original 44
for file in $(find ~/eusociality/results/busco_results/2021-09-20/hymenoptera_ncbi_annotated_01/*/run*/ -name "full_table*.tsv"); do grep -v "^#" ${file} | awk '$2=="Complete" {print $1}' >> complete_busco_ids.txt; done # the new 5
grep -v "^#" ~/eusociality/results/busco_results/2021-09-23/bombus_pyrosoma_busco/run_hymenoptera_odb10/full_table.tsv | awk '$2=="Complete" {print $1}' >> complete_busco_ids.txt # Bombus pyrosoma
grep -v "^#" ~/eusociality/results/busco_results/2021-09-24/vespula_pensylvanica_busco/run_hymenoptera_odb10/full_table.tsv | awk '$2=="Complete" {print $1}' >> complete_busco_ids.txt # Vespula pensylvanica

# get the counts for each unique BUSCO id
sort complete_busco_ids.txt | uniq -c > complete_busco_ids_with_counts.txt

# filter all ids with a count < 51 
# means we only keep those which are complete in all species
awk '$1 > 50 && $1 < 52 {print $2}' complete_busco_ids_with_counts.txt > final_busco_ids_complete_in_51.txt

# generate the input file for the python script
# getting the busco id, protein id and genome file name
for file in $(find ~/eusociality/results/busco_results/2021-08-10/hymenoptera_all_annotated/*/run* -name "full_table*.tsv"); do short=$(echo "${file#*hymenoptera_all_annotated/}"); echo "${short%%\.*}" >> protein_ids_complete_in_51.txt; for id in $(cat final_busco_ids_complete_in_51.txt); do grep -v "^#" ${file} | awk -v id="$id" '{OFS="|"} {if ($1==id) print $1,$3}' >> protein_ids_complete_in_51.txt; done; done # original 44
for file in $(find ~/eusociality/results/busco_results/2021-09-20/hymenoptera_ncbi_annotated_01/*/run* -name "full_table*.tsv"); do short=$(echo "${file#*hymenoptera_ncbi_annotated_01/}"); echo "${short%%\.*}" >> protein_ids_complete_in_51.txt; for id in $(cat final_busco_ids_complete_in_51.txt); do grep -v "^#" ${file} | awk -v id="$id" '{OFS="|"} {if ($1==id) print $1,$3}' >> protein_ids_complete_in_51.txt; done; done # new 5
echo GCF_014825855 >> protein_ids_complete_in_51.txt && for id in $(cat final_busco_ids_complete_in_51.txt); do grep -v "^#" ~/eusociality/results/busco_results/2021-09-23/bombus_pyrosoma_busco/run_hymenoptera_odb10/full_table.tsv | awk -v id="$id" '{OFS="|"} {if ($1==id) print $1,$3}' >> protein_ids_complete_in_51.txt; done # Bombus pyrosoma
echo GCF_014466175 >> protein_ids_complete_in_51.txt && for id in $(cat final_busco_ids_complete_in_51.txt); do grep -v "^#" ~/eusociality/results/busco_results/2021-09-24/vespula_pensylvanica_busco/run_hymenoptera_odb10/full_table.tsv | awk -v id="$id" '{OFS="|"} {if ($1==id) print $1,$3}' >> protein_ids_complete_in_51.txt; done

# created temporary directories to store the longest cds and protein data
# and copied that data there
mkdir tmp && mkdir tmp/cds tmp/prot genes

# FOR THE LONGEST CDSs
cp ~/eusociality/data/hymenoptera/2019-11-01/longest/hymenoptera_longest_original.tar.gz tmp/cds/
cd tmp/cds
tar -xvzf hymenoptera_longest_original.tar.gz && rm hymenoptera_longest_original.tar.gz
# removing genomes that were excluded from the analyzes
rm GCF_000648655.2_Cflo_2.0_genomic.gbff_nt.fasta.longest.fasta GCF_000214255.1_Bter_1.0_genomic.gbff_nt.fasta.longest.fasta GCF_000503995.1_CerSol_1.0_genomic.gbff_nt.fasta.longest.fasta GCF_001263275.1_ASM126327v1_genomic.gbff_nt.fasta.longest.fasta GCF_000002325.3_Nvit_2.1_genomic.gbff_nt.fasta.longest.fasta GCF_003672135.1_Obir_v5.4_genomic.gbff_nt.fasta.longest.fasta GCF_000187915.1_Pbar_UMD_V03_genomic.gbff_nt.fasta.longest.fasta GCF_003070985.1_ASM307098v1_genomic.gbff_nt.fasta.longest.fasta 
GCF_000949405.1_V.emery_V1.0_genomic.gbff_nt.fasta.longest.fasta
cp ~/eusociality/data/hymenoptera/2021-01-28/longest/longest.tar.gz .
tar -xvzf longest.tar.gz && rm longest.tar.gz
# removing genomes that were excluded from the analyzes
rm GCF_005281655.1_TAMU_Nfulva_1.0_genomic.gbff_nt.fasta.longest
cp ~/eusociality/data/hymenoptera/2021-09-18/longest/* .
cp ~/eusociality/data/hymenoptera/2021-09-20/longest/GCF_011392965.1_Fvar_1.2_genomic.gbff_nt.fasta.longest .
cp ~/eusociality/data/hymenoptera/2021-09-23/longest/GCF_014825855.1_ASM1482585v1_genomic.gbff_nt.fasta.longest .
cp ~/eusociality/data/hymenoptera/2021-09-24/longest/GCF_014466175.1_ASM1446617v1_genomic.gbff_nt.fasta.longest .

# FOR THE PROTEINS
cd ../prot/
cp ~/eusociality/data/hymenoptera/2019-11-07/proteins/hymenoptera_proteins_34.tar.gz .
tar -xvzf hymenoptera_proteins_34.tar.gz && rm hymenoptera_proteins_34.tar.gz
# removing proteomes that were excluded from the analyzes
rm GCF_000648655.2_Cflo_2.0_genomic.gbff_nt.fasta.longest.fasta.ids.txt.aa.fa
cp ~/eusociality/data/hymenoptera/2021-01-28/proteins/* .
# removing proteomes that were excluded from the analyzes
rm GCF_005281655.1_TAMU_Nfulva_1.0_genomic.gbff_nt.fasta.longest.ids.aa.fa
cp ~/eusociality/data/hymenoptera/2021-09-18/proteins/* .
cp ~/eusociality/data/hymenoptera/2021-09-20/proteins/GCF_011392965.1_Fvar_1.2_genomic.gbff_nt.fasta.longest.ids.aa.fa .
cp ~/eusociality/data/hymenoptera/2021-09-23/proteins/GCF_014825855.1_ASM1482585v1_genomic.gbff_nt.fasta.longest.ids.aa.fa .
cp ~/eusociality/data/hymenoptera/2021-09-24/proteins/GCF_014466175.1_ASM1446617v1_genomic.gbff_nt.fasta.longest.ids.aa.fa .

# ran the python script to generate separate files for each ortholog
# complete in all species, containing the sequences for all 51 species
# for proteins and CDSs
python3.6 ~/eusociality/bin/utils/get_busco_genes.py protein_ids_complete_in_51.txt tmp/cds/ tmp/prot/ genes/

# checked that all generated files have 51 sequences each
grep -c ">" genes/* | awk -F":" '{OFS=":"} {if ($2 != 51) print $1,$2}'
```
- Fixed the `run_alignments.sh` script, correcting the output extension to `.fas`, and moved it to `/home/maycon/eusociality/bin/utils` (also moved `get_busco_genes.py` there);
- Ran alignments for all CDSs using MAFFT with the `--auto` option (add this to the paper methodology):
```bash
nice -n 10 time ~/eusociality/bin/utils/./run_alignments.sh genes/ alignments/ 50
```
- Updated the script to fetch the OrthoDB data for the BUSCO orthologs and ran it locally to download the data for the 1024 genes complete in all 51 species:
```bash
# in /mnt/2A2A43C42A438C2F/lab_data/busco_genes
scp -P 2772 maycon@150.164.28.21:/home/maycon/eusociality/work/busco_phylo/2021-09-24/final_busco_ids_complete_in_51.txt .

# in /home/maycon/Documents/LAB/eusociality/local_work
python get_ortodb_data.py /mnt/2A2A43C42A438C2F/lab_data/busco_genes/final_busco_ids_complete_in_51.txt 4 orthodb_info_buscos_complete_in_51.tsv
# uploaded the info file to the server just as a backup
scp -P 2772 orthodb_info_buscos_complete_in_51.tsv maycon@150.164.28.21:/home/maycon/eusociality/work/busco_phylo/2021-09-24/
mv orthodb_info_buscos_complete_in_51.tsv /mnt/2A2A43C42A438C2F/lab_data/busco_genes
```